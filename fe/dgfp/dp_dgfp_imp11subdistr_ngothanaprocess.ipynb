{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance 11 Subdistricts: ngothana_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance11 Subdistricts: ngothana_process\n",
    "- DONE: Step 1: List all files and check if empty. Subset based on emptyness\n",
    "- DONE: Step 2: Read file and add file name, split file name to additional columns and add column with path\n",
    "- DONE: Step 3: Define variables and if necessary to calculate relative values\n",
    "- DONE: Step 4: Determine how to sumarize columns if possible to sum or average and do so\n",
    "- DONE: Step 5: Break data by years\n",
    "- DONE: Step 6: Summarize data by zilas. Keep numeric variables, division, zila and year\n",
    "- DONE: Step 7: Create file with zilas, division and \n",
    "- DONE: Step 8: Write everything to the output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variables:\n",
    "    - **thana**:\n",
    "    - **ECouple**: \n",
    "    - **Pill**:\n",
    "    - **Condom**:\n",
    "    - **Injectable**: \n",
    "    - **IUD**: \n",
    "    - **Implant**:\n",
    "    - **PerMale**: \n",
    "    - **PerFemale**:\n",
    "    - **Tpermanent**: \n",
    "    - **GrandTotal**:\n",
    "    - **CAR**:\n",
    "    - **Unnamed: 12**:\n",
    "    - **full_name_path**: \n",
    "    - **file_name1**: \n",
    "    - **file_name2**:\n",
    "    - **year**: \n",
    "    - **month**: \n",
    "    - **upazila**: \n",
    "    - **division**: \n",
    "    - **upazila_full**:\n",
    "- Indicators:\n",
    "    - Percent_Pill = Pill/GrandTotal\n",
    "    - Percent_Condom = Condom/GrandTotal\n",
    "    - Percent_Injectable = Injectable/GrandTotal\n",
    "    - Percent_IUD = IUD/GrandTotal\n",
    "    - Percent_Implant = Implant/GrandTotal\n",
    "    - Percent_PerMale = PerMale/Tpermanent\n",
    "    - Percent_PerFemale = PerFemale/Tpermanent\n",
    "    - CAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '/Users/edinhamzic/Symphony/wb_bangladesh/Bangladesh/data/dgfp/data/importance11_subdistricts/ngothana_process'\n",
    "GEO = '/Users/edinhamzic/Symphony/wb_bangladesh/Bangladesh/output/dgfp/geos/dgfp_geo.csv'\n",
    "OUT = '/Users/edinhamzic/Symphony/wb_bangladesh/Bangladesh/output/dgfp/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    files_list = []\n",
    "    for path, subdirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if bool(re.search(pattern=r'.csv', string=file)):\n",
    "                files_list.append(os.path.join(path, file))\n",
    "    return files_list\n",
    "    \n",
    "def read_arrange_files(files_list):\n",
    "    data_list = {}\n",
    "    log_columns = ['empty', 'full_name_path', 'file_name1', 'file_name2',\n",
    "                   'year', 'month', 'upazila', 'division', 'upazila_full']\n",
    "    log_array = []\n",
    "    for file in files_list:\n",
    "        tmp = pd.read_csv(file, sep='\\t', skiprows=1)\n",
    "        log_list = []\n",
    "        log_list.append(tmp.empty)\n",
    "        if tmp.empty:\n",
    "            log_list.append(file)\n",
    "            log_list.append(os.path.split(file)[1])\n",
    "            name = os.path.split(file)[1]\n",
    "            name = name.replace(\".csv\", \"\")\n",
    "            log_list.append(name)\n",
    "            name_split = name.split(\"-\")\n",
    "            log_list.append(name_split[0])\n",
    "            log_list.append(name_split[1])\n",
    "            log_list.append(name_split[3])\n",
    "            log_list.append(name_split[4])\n",
    "            log_list.append(name_split[4]+name_split[3])\n",
    "        else:\n",
    "            tmp['full_name_path'] = file\n",
    "            log_list.append(file)\n",
    "            tmp['file_name1'] = os.path.split(file)[1]\n",
    "            log_list.append(os.path.split(file)[1])\n",
    "            name = os.path.split(file)[1]\n",
    "            name = name.replace(\".csv\", \"\")\n",
    "            tmp['file_name2'] = name\n",
    "            log_list.append(name)\n",
    "            name_split = name.split(\"-\")\n",
    "            tmp['year'] = int(name_split[0])\n",
    "            log_list.append(name_split[0])\n",
    "            tmp['month'] = int(name_split[1])\n",
    "            log_list.append(name_split[1])\n",
    "            tmp['upazila'] = name_split[3]\n",
    "            log_list.append(name_split[3])\n",
    "            tmp['division'] = name_split[4]\n",
    "            log_list.append(name_split[4])\n",
    "            tmp['upazila_full'] = name_split[4]+name_split[3]\n",
    "            log_list.append(name_split[4]+name_split[3])\n",
    "            data_list[name] = tmp\n",
    "        log_array.append(log_list)\n",
    "    return data_list, pd.DataFrame(log_array, columns=log_columns)\n",
    "\n",
    "def concat_data(ddict):\n",
    "    out_list = []\n",
    "    for key, value in ddict.items():\n",
    "        out_list.append(value)\n",
    "    df = pd.concat(out_list, axis=0)\n",
    "    return df\n",
    "\n",
    "def break_by_years(input_df, year_var):\n",
    "    df = input_df.copy(deep=True)\n",
    "    out_dict = {}\n",
    "    for year in df[year_var].unique():\n",
    "        out_dict[str(year)] = df[df[year_var] == year]\n",
    "    return out_dict\n",
    "\n",
    "def summarize_zilas(data_dict):\n",
    "    out_dict = {}\n",
    "    for key, value in data_dict.items():\n",
    "        tmp = value.copy(deep=True)\n",
    "        subset_vars = ['upazila', 'division', 'ECouple', 'Pill', 'Condom', 'Injectable', 'IUD',\n",
    "                       'Implant','PerMale', 'PerFemale', 'Tpermanent', 'GrandTotal']\n",
    "        tmp = tmp[subset_vars]\n",
    "        tmp = tmp.groupby('upazila').sum()\n",
    "        tmp = tmp.reset_index()\n",
    "        out_dict[key] = tmp\n",
    "    return out_dict\n",
    "\n",
    "\n",
    "def calculate_indicators(data_dict):\n",
    "    out_dict = {}\n",
    "    for key, value in data_dict.items():\n",
    "        tmp = value.copy(deep=True)\n",
    "        tmp['NGO_Percent_Pill'] = np.round(tmp['Pill']/tmp['GrandTotal']*100, 2)\n",
    "        tmp['NGO_Percent_Condom'] = np.round(tmp['Condom']/tmp['GrandTotal']*100, 2)\n",
    "        tmp['NGO_Percent_Injectable'] = np.round(tmp['Injectable']/tmp['GrandTotal']*100, 2)\n",
    "        tmp['NGO_Percent_IUD'] = np.round(tmp['IUD']/tmp['GrandTotal']*100, 2)\n",
    "        tmp['NGO_Percent_Implant'] = np.round(tmp['Implant']/tmp['GrandTotal']*100, 2)\n",
    "        tmp['NGO_Percent_PerMale'] = np.round(tmp['PerMale']/tmp['GrandTotal']*100, 2)\n",
    "        tmp['NGO_Percent_PerFemale'] = np.round(tmp['PerFemale']/tmp['GrandTotal']*100, 2)\n",
    "        tmp['NGO_CAR'] = np.round(tmp['GrandTotal']/tmp['ECouple']*100, 2)\n",
    "        tmp = tmp[['upazila', 'NGO_Percent_Pill', 'NGO_Percent_Condom', 'NGO_Percent_Injectable', \n",
    "                   'NGO_Percent_IUD', 'NGO_Percent_Implant', 'NGO_Percent_PerMale',\n",
    "                   'NGO_Percent_PerFemale', 'NGO_CAR',]]\n",
    "        out_dict[key] = tmp\n",
    "    return out_dict\n",
    "\n",
    "def update_geos(datad, geo_df):\n",
    "    out = {}\n",
    "    for key, value in datad.items():\n",
    "        tmp = geo_df.merge(value, how='left', left_on='upazila_dgfp', right_on='upazila')\n",
    "        out[key] = tmp\n",
    "    return out\n",
    "\n",
    "\n",
    "def clean_up(data_dict):\n",
    "    out = {}\n",
    "    for key, value in data_dict.items():\n",
    "        tmp = value\n",
    "        tmp['geo'] = tmp['division_geo'].str.cat(tmp['zila_geo'], sep=\"\")\n",
    "        tmp = value.drop(['upazila_dgfp', 'division_dgfp', 'upazila_full_dgfp', 'division_geo',\n",
    "                          'division', 'zila_geo','zila','upazila'], axis=1)\n",
    "        out[key] = tmp\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_files(path=DATA) \n",
    "data, log = read_arrange_files(files_list=files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>empty</th>\n",
       "      <th>full_name_path</th>\n",
       "      <th>file_name1</th>\n",
       "      <th>file_name2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>upazila</th>\n",
       "      <th>division</th>\n",
       "      <th>upazila_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2010-4-28-0602-06.csv</td>\n",
       "      <td>2010-4-28-0602-06</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>0602</td>\n",
       "      <td>06</td>\n",
       "      <td>060602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2013-9-28-0304-03.csv</td>\n",
       "      <td>2013-9-28-0304-03</td>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>0304</td>\n",
       "      <td>03</td>\n",
       "      <td>030304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2014-5-28-0106-07.csv</td>\n",
       "      <td>2014-5-28-0106-07</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>0106</td>\n",
       "      <td>07</td>\n",
       "      <td>070106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2014-11-28-0109-01.csv</td>\n",
       "      <td>2014-11-28-0109-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "      <td>0109</td>\n",
       "      <td>01</td>\n",
       "      <td>010109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2018-10-28-0507-05.csv</td>\n",
       "      <td>2018-10-28-0507-05</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0507</td>\n",
       "      <td>05</td>\n",
       "      <td>050507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    empty                                     full_name_path  \\\n",
       "2    True  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...   \n",
       "3    True  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...   \n",
       "13   True  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...   \n",
       "18   True  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...   \n",
       "22   True  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...   \n",
       "\n",
       "                file_name1          file_name2  year month upazila division  \\\n",
       "2    2010-4-28-0602-06.csv   2010-4-28-0602-06  2010     4    0602       06   \n",
       "3    2013-9-28-0304-03.csv   2013-9-28-0304-03  2013     9    0304       03   \n",
       "13   2014-5-28-0106-07.csv   2014-5-28-0106-07  2014     5    0106       07   \n",
       "18  2014-11-28-0109-01.csv  2014-11-28-0109-01  2014    11    0109       01   \n",
       "22  2018-10-28-0507-05.csv  2018-10-28-0507-05  2018    10    0507       05   \n",
       "\n",
       "   upazila_full  \n",
       "2        060602  \n",
       "3        030304  \n",
       "13       070106  \n",
       "18       010109  \n",
       "22       050507  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log['empty'].value_counts()\n",
    "log_true = log[log['empty'] == True]\n",
    "display(log_true.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data by years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015    243\n",
      "2018    212\n",
      "2013    189\n",
      "2014    186\n",
      "2012    170\n",
      "2008    104\n",
      "2011     89\n",
      "2009     65\n",
      "2010     56\n",
      "2017     11\n",
      "2016      8\n",
      "Name: year, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(log_true['year'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data by months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    159\n",
      "11    151\n",
      "12    148\n",
      "5     117\n",
      "2     115\n",
      "6      98\n",
      "9      95\n",
      "4      93\n",
      "7      93\n",
      "3      91\n",
      "8      87\n",
      "1      86\n",
      "Name: month, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(log_true['month'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data by divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "05    258\n",
      "07    226\n",
      "06    222\n",
      "04    174\n",
      "02    169\n",
      "01    128\n",
      "08     82\n",
      "03     74\n",
      "Name: division, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(log_true['division'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29260, 21)\n"
     ]
    }
   ],
   "source": [
    "data_df = concat_data(ddict=data)\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thana</th>\n",
       "      <th>ECouple</th>\n",
       "      <th>Pill</th>\n",
       "      <th>Condom</th>\n",
       "      <th>Injectable</th>\n",
       "      <th>IUD</th>\n",
       "      <th>Implant</th>\n",
       "      <th>PerMale</th>\n",
       "      <th>PerFemale</th>\n",
       "      <th>Tpermanent</th>\n",
       "      <th>...</th>\n",
       "      <th>CAR</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>full_name_path</th>\n",
       "      <th>file_name1</th>\n",
       "      <th>file_name2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>upazila</th>\n",
       "      <th>division</th>\n",
       "      <th>upazila_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Panchgarh Sadar</td>\n",
       "      <td>8695</td>\n",
       "      <td>3479</td>\n",
       "      <td>842</td>\n",
       "      <td>1265</td>\n",
       "      <td>116</td>\n",
       "      <td>368</td>\n",
       "      <td>218</td>\n",
       "      <td>679</td>\n",
       "      <td>897</td>\n",
       "      <td>...</td>\n",
       "      <td>80.1265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2012-9-28-0103-07.csv</td>\n",
       "      <td>2012-9-28-0103-07</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>0103</td>\n",
       "      <td>07</td>\n",
       "      <td>070103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atowari</td>\n",
       "      <td>9493</td>\n",
       "      <td>3363</td>\n",
       "      <td>274</td>\n",
       "      <td>1555</td>\n",
       "      <td>401</td>\n",
       "      <td>266</td>\n",
       "      <td>774</td>\n",
       "      <td>737</td>\n",
       "      <td>1511</td>\n",
       "      <td>...</td>\n",
       "      <td>77.6362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2012-9-28-0103-07.csv</td>\n",
       "      <td>2012-9-28-0103-07</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>0103</td>\n",
       "      <td>07</td>\n",
       "      <td>070103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debiganj</td>\n",
       "      <td>11190</td>\n",
       "      <td>3979</td>\n",
       "      <td>283</td>\n",
       "      <td>3035</td>\n",
       "      <td>211</td>\n",
       "      <td>95</td>\n",
       "      <td>740</td>\n",
       "      <td>287</td>\n",
       "      <td>1027</td>\n",
       "      <td>...</td>\n",
       "      <td>77.1224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2012-9-28-0103-07.csv</td>\n",
       "      <td>2012-9-28-0103-07</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>0103</td>\n",
       "      <td>07</td>\n",
       "      <td>070103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Moheshpur</td>\n",
       "      <td>14440</td>\n",
       "      <td>4864</td>\n",
       "      <td>930</td>\n",
       "      <td>3234</td>\n",
       "      <td>652</td>\n",
       "      <td>410</td>\n",
       "      <td>81</td>\n",
       "      <td>1249</td>\n",
       "      <td>1330</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2013-1-28-0204-02.csv</td>\n",
       "      <td>2013-1-28-0204-02</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0204</td>\n",
       "      <td>02</td>\n",
       "      <td>020204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jhenaidaha Sadar</td>\n",
       "      <td>16230</td>\n",
       "      <td>6735</td>\n",
       "      <td>1633</td>\n",
       "      <td>2844</td>\n",
       "      <td>196</td>\n",
       "      <td>229</td>\n",
       "      <td>65</td>\n",
       "      <td>658</td>\n",
       "      <td>723</td>\n",
       "      <td>...</td>\n",
       "      <td>76.1553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/Bangl...</td>\n",
       "      <td>2013-1-28-0204-02.csv</td>\n",
       "      <td>2013-1-28-0204-02</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0204</td>\n",
       "      <td>02</td>\n",
       "      <td>020204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              thana  ECouple  Pill  Condom  Injectable  IUD  Implant  PerMale  \\\n",
       "0   Panchgarh Sadar     8695  3479     842        1265  116      368      218   \n",
       "1           Atowari     9493  3363     274        1555  401      266      774   \n",
       "2          Debiganj    11190  3979     283        3035  211       95      740   \n",
       "0         Moheshpur    14440  4864     930        3234  652      410       81   \n",
       "1  Jhenaidaha Sadar    16230  6735    1633        2844  196      229       65   \n",
       "\n",
       "   PerFemale  Tpermanent     ...           CAR  Unnamed: 12  \\\n",
       "0        679         897     ...       80.1265          NaN   \n",
       "1        737        1511     ...       77.6362          NaN   \n",
       "2        287        1027     ...       77.1224          NaN   \n",
       "0       1249        1330     ...       79.0859          NaN   \n",
       "1        658         723     ...       76.1553          NaN   \n",
       "\n",
       "                                      full_name_path             file_name1  \\\n",
       "0  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...  2012-9-28-0103-07.csv   \n",
       "1  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...  2012-9-28-0103-07.csv   \n",
       "2  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...  2012-9-28-0103-07.csv   \n",
       "0  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...  2013-1-28-0204-02.csv   \n",
       "1  /Users/edinhamzic/Symphony/wb_bangladesh/Bangl...  2013-1-28-0204-02.csv   \n",
       "\n",
       "          file_name2  year  month  upazila division upazila_full  \n",
       "0  2012-9-28-0103-07  2012      9     0103       07       070103  \n",
       "1  2012-9-28-0103-07  2012      9     0103       07       070103  \n",
       "2  2012-9-28-0103-07  2012      9     0103       07       070103  \n",
       "0  2013-1-28-0204-02  2013      1     0204       02       020204  \n",
       "1  2013-1-28-0204-02  2013      1     0204       02       020204  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['thana', 'ECouple', 'Pill', 'Condom', 'Injectable', 'IUD', 'Implant',\n",
       "       'PerMale', 'PerFemale', 'Tpermanent', 'GrandTotal', 'CAR',\n",
       "       'Unnamed: 12', 'full_name_path', 'file_name1', 'file_name2', 'year',\n",
       "       'month', 'upazila', 'division', 'upazila_full'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data_df.head())\n",
    "data_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break data by years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2012', '2013', '2011', '2008', '2018', '2016', '2017', '2010', '2015', '2009', '2014'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datad = break_by_years(input_df=data_df, year_var='year')\n",
    "datad.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "(62, 9)\n",
      "2013\n",
      "(55, 9)\n",
      "2011\n",
      "(60, 9)\n",
      "2008\n",
      "(60, 9)\n",
      "2018\n",
      "(62, 9)\n",
      "2016\n",
      "(64, 9)\n",
      "2017\n",
      "(64, 9)\n",
      "2010\n",
      "(61, 9)\n",
      "2015\n",
      "(55, 9)\n",
      "2009\n",
      "(61, 9)\n",
      "2014\n",
      "(58, 9)\n"
     ]
    }
   ],
   "source": [
    "data = summarize_zilas(data_dict=datad)\n",
    "data = calculate_indicators(data_dict=data)\n",
    "for key, value in data.items():\n",
    "    print(key)\n",
    "    print(value.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29260, 7)\n",
      "(64, 7)\n"
     ]
    }
   ],
   "source": [
    "dgfp_geo = pd.read_csv(GEO)\n",
    "dgfp_geo['upazila_dgfp'] = dgfp_geo['upazila_dgfp'].astype(str).str.pad(width=4, side='left', fillchar='0')\n",
    "dgfp_geo['division_dgfp'] = dgfp_geo['division_dgfp'].astype(str).str.pad(width=2, side='left', fillchar='0')\n",
    "dgfp_geo['upazila_full_dgfp'] = dgfp_geo['upazila_full_dgfp'].astype(str).str.pad(width=6, side='left', fillchar='0')\n",
    "dgfp_geo['division_geo'] = dgfp_geo['division_geo'].astype(str).str.pad(width=2, side='left', fillchar='0')\n",
    "dgfp_geo['zila_geo'] = dgfp_geo['zila_geo'].astype(str).str.pad(width=2, side='left', fillchar='0')\n",
    "dgfp_geo = dgfp_geo.drop(['thana_dgfp', 'Unnamed: 8'], axis=1)\n",
    "print(dgfp_geo.shape)\n",
    "dgfp_geo.head()\n",
    "dgfp_geo = dgfp_geo.drop_duplicates()\n",
    "print(dgfp_geo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "(62, 9)\n",
      "(64, 16)\n",
      "2013\n",
      "(55, 9)\n",
      "(64, 16)\n",
      "2011\n",
      "(60, 9)\n",
      "(64, 16)\n",
      "2008\n",
      "(60, 9)\n",
      "(64, 16)\n",
      "2018\n",
      "(62, 9)\n",
      "(64, 16)\n",
      "2016\n",
      "(64, 9)\n",
      "(64, 16)\n",
      "2017\n",
      "(64, 9)\n",
      "(64, 16)\n",
      "2010\n",
      "(61, 9)\n",
      "(64, 16)\n",
      "2015\n",
      "(55, 9)\n",
      "(64, 16)\n",
      "2009\n",
      "(61, 9)\n",
      "(64, 16)\n",
      "2014\n",
      "(58, 9)\n",
      "(64, 16)\n"
     ]
    }
   ],
   "source": [
    "data = update_geos(datad=data, geo_df=dgfp_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up before writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean_up(data_dict=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_out(data_dict, out_dir):\n",
    "    out = {}\n",
    "    for key, value in data_dict.items():\n",
    "        value.to_csv(path_or_buf=os.path.join(out_dir, \"data_dgfp_imp11subdistr_ngothanaprocess_\" + str(key) + \".csv\"), \n",
    "                    index=False, index_label=False)\n",
    "write_out(data_dict=data, out_dir=OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dgfp_imp11subdist_years = break_by_years(data_dict=dgfp_imp11subdist, start_year=2008, end_year=2018, year_var='Year')\n",
    "dgfp_imp11subdist_data = summarize_data(data_dict = dgfp_imp11subdist_years, index_vars=['thana_Name', 'thana', 'Year', 'District', 'Division', 'program'])\n",
    "data = merge_by_years(dgfp_imp11subdist_data)  \n",
    "def dgfp_geos(data_dict, geo_vars):\n",
    "    out = {}\n",
    "    for key, value in data_dict.items():\n",
    "        subset = list(set(geo_vars).intersection(set(value.columns)))\n",
    "        tmp = value[subset]\n",
    "        tmp = tmp.drop_duplicates()\n",
    "        out[key] = tmp\n",
    "    return out\n",
    "        \n",
    "t = dgfp_geos(data_dict=dgfp_imp11subdist, geo_vars = ['thana_Name', 'thana', 'District', 'Division', 'program'])\n",
    "for k,v in t.items():\n",
    "    print(\"#\"*100)\n",
    "    print(k)\n",
    "    print(v.shape)\n",
    "    display(v.head())\n",
    "t['../../data/dgfp/data/importance11_subdistricts/thana_process'].to_csv(\"../../dgfp_geo.csv\")\n",
    "def merge_by_years(data_dict):\n",
    "    out = {}\n",
    "    for year, data in data_dict.items():\n",
    "        out[year] = pd.concat([v for k,v in data.items()], axis=1, sort=True, join='outer',)\n",
    "    return out\n",
    "\n",
    "def read_data_dir(data_dirs, ext):\n",
    "    data_dict= {}\n",
    "    dirs = pd.read_csv(data_dirs, header=None, names=['dirs'])\n",
    "    for folder in dirs['dirs']:\n",
    "        # print(folder)\n",
    "        data_dict[folder] = read_data(path=folder, ext=ext)\n",
    "    return data_dict\n",
    "    \n",
    "def summarize_data(data_dict, index_vars):\n",
    "    years_dict = {}\n",
    "    for key, value in data_dict.items():\n",
    "        years_dict[key] = {}\n",
    "        for program, df in value.items():\n",
    "            tmp_index = list(set(index_vars).intersection(set(df.columns)))\n",
    "            df = df.set_index(tmp_index)\n",
    "            df = df[list(df.dtypes[df.dtypes == 'float64'].index)]\n",
    "            try:\n",
    "                df = df.groupby(['thana']).sum()\n",
    "            except KeyError:\n",
    "                df = df.groupby(['thana_Name']).sum()\n",
    "            df.columns = [var + \"_\" + program.split(\"/\")[-1] for var in df.columns]\n",
    "            years_dict[key][program] = df\n",
    "    return years_dict \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
