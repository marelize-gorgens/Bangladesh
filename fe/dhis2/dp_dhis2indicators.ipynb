{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - DHIS2 Data - Health Indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Input data**: Data downloaded via API from DHIS2 System. This data is stored in *data/dhis2/data* directories\n",
    "- **Processing**:\n",
    "    - Getting Upazila and District level data\n",
    "    - Reading and processing and transforming data in the following form:\n",
    "        - Rows: *Geographical levels (upazila and districts)*\n",
    "        - Columns: *Variables/health indicators*\n",
    "        - Datasets: *Years [2009 - 2018]*\n",
    "- **Output data**: Processed data is stored in *data/output/dhis2/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    \"\"\"\n",
    "    Function gets the list of all file from the target directory,\n",
    "    takes absolute path, splits file names to extract:\n",
    "    - File name\n",
    "    - Data element\n",
    "    - File type\n",
    "    - Year\n",
    "    - Geographical level/group\n",
    "    - Absolute path of the file name\n",
    "    Returns all this as a dataframe\n",
    "    \"\"\"\n",
    "    path_all = os.path.join(path, '*')\n",
    "    abs_file_names = glob.glob(path_all, recursive=True)\n",
    "    file_names = [os.path.split(glob.glob(file_path)[0])[1] for file_path in abs_file_names]\n",
    "    data_collection = [file_name.split(\"_\")[0] for file_name in file_names]\n",
    "    year = [file_name.split(\"_\")[1] for file_name in file_names]\n",
    "    geo_level = [file_name.split(\"_\")[2] for file_name in file_names]\n",
    "    file_type = [file_name[-8:-4] for file_name in file_names]\n",
    "    files_df = pd.DataFrame.from_dict({'file_names': file_names, \n",
    "                                       'data_collection': data_collection,\n",
    "                                       'year': year,\n",
    "                                       'geo_level': geo_level,\n",
    "                                       'file_type': file_type,\n",
    "                                       'abs_file_names': abs_file_names\n",
    "                                      })\n",
    "\n",
    "    return files_df\n",
    "\n",
    "def create_sets(input_df, geo_levels, years, file_types):\n",
    "    \"\"\"\n",
    "    input_df: Output from function list_files()\n",
    "    geo_levels: Defining geographic levels:\n",
    "                If as a list than it is a subset of geo levels from input_df\n",
    "                Otherwise it should ba string that specifies the column name\n",
    "    years: Defining years:\n",
    "           If as a list than it is a subset of geo levels from input_df\n",
    "           Otherwise it should ba string that specifies the column name\n",
    "    file_types: Either NAME or CODE. This is defined in the rawfiles.\n",
    "                NAME: Descriptive name of geographical unit as key ID variable\n",
    "                CODE: Geo-level code of geogrpahical unit as key ID variable\n",
    "    return: Dictionary by geo-level, year and file type\n",
    "    \"\"\"\n",
    "    df = input_df.copy(deep=True)\n",
    "    datasets = {}\n",
    "    if ((type(geo_levels) == list) & (type(years) == list)):\n",
    "        for geo_level in geo_levels:\n",
    "            for year in years:\n",
    "                for file_type in file_types:\n",
    "                    name = geo_level + '_' + year + '_' + file_type\n",
    "                    datasets[name] = df[(df['geo_level']==geo_level) &\n",
    "                                        (df['year']==year) & \n",
    "                                        (df['file_type']==file_type)] \n",
    "    else:\n",
    "        for geo_level in df[geo_levels].unique():\n",
    "            for year in df[years].unique():\n",
    "                for file_type in file_types:\n",
    "                    name = geo_level + '_' + year + '_' + file_type\n",
    "                    datasets[name] = df[(df['geo_level']==geo_level) & \n",
    "                                        (df['year']==year) & \n",
    "                                        (df['file_type']==file_type)]\n",
    "    return datasets\n",
    "\n",
    "def select_sets(datasets):\n",
    "    \"\"\"\n",
    "    datasets: Output from function create_sets\n",
    "    returns\n",
    "        - Data dictionary with loaded datasets by geo-level and year\n",
    "        # - Data frame with two columns:\n",
    "            # - List of file names with absolute paths\n",
    "            # - Logical column whether the loaded file is empty or not\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    # summary_df = {'filenames': list(), 'emptyness': list()}\n",
    "    for key, item in datasets.items():\n",
    "        data_dict[key] = dict()\n",
    "        for i in item.index:\n",
    "            tmp = pd.read_csv(item['abs_file_names'][i])\n",
    "            # summary_df['filenames'].append(os.path.split(item['abs_file_names'][i])[1])\n",
    "            # summary_df['emptyness'].append(tmp.empty)\n",
    "            data_dict[key][item['data_collection'][i]] = tmp\n",
    "    return data_dict # pd.DataFrame(summary_df)\n",
    "\n",
    "\n",
    "def extract_variables(data_dict):\n",
    "    \"\"\"\n",
    "    data_dict: Output from select_sets function\n",
    "    returns: Dataframe that summarizes all loaded files and includes following columns:\n",
    "        - variable_name: variable names if datasets is not empty otherwise it states 'No Variables'\n",
    "        - data_element: What data element from DHIS2 loaded datasets corresponds to\n",
    "        - is_empty: Is it empty or not\n",
    "        - geo_level: for example upazila or zilla\n",
    "        - year: 2009 - 2018\n",
    "    \"\"\"\n",
    "    output_dict = {'year':[], 'data_element':[], 'geo_level':[], 'var_name':[], 'is_empty':[]}\n",
    "    for key_dict, item_dict in data_dict.items():\n",
    "        for key, item in data_dict[key_dict].items():\n",
    "            if item.empty:\n",
    "                output_dict['var_name'].append('No Variables')\n",
    "                output_dict['data_element'].append(key)\n",
    "                output_dict['is_empty'].append(True)\n",
    "                output_dict['geo_level'].append(key_dict.split(\"_\")[1])\n",
    "                output_dict['year'].append(key_dict.split(\"_\")[0])\n",
    "            else:\n",
    "                for var in item['Data'].unique():\n",
    "                    output_dict['var_name'].append(var)\n",
    "                    output_dict['data_element'].append(key)\n",
    "                    output_dict['is_empty'].append(item.empty)\n",
    "                    output_dict['geo_level'].append(key_dict.split(\"_\")[1])\n",
    "                    output_dict['year'].append(key_dict.split(\"_\")[0])\n",
    "        return pd.DataFrame.from_dict(output_dict)\n",
    "\n",
    "    \n",
    "def transform_data(data_dict):\n",
    "    \"\"\"\n",
    "    data_dict: Output from function select_sets\n",
    "    returns: Dictionary (by geo-level and year) of pivoted dataframes which are not empty\n",
    "    \"\"\"\n",
    "    tdata_dict = {}\n",
    "    for key_dict, item_dict in data_dict.items():\n",
    "        tdata_dict[key_dict] = list()\n",
    "        for key, item in data_dict[key_dict].items():\n",
    "            if item.empty:\n",
    "                print('Provided dataframe is empty and therefore is not processed')\n",
    "            else:\n",
    "                tmp = pd.pivot_table(data=item, \n",
    "                                     values='Value', \n",
    "                                     index='Organisation unit',\n",
    "                                     columns='Data', \n",
    "                                     aggfunc='first')\n",
    "                tmp.columns = key + \": \" + tmp.columns\n",
    "                tdata_dict[key_dict].append(tmp)\n",
    "    return tdata_dict\n",
    "\n",
    "\n",
    "def merge_data(data_dict):\n",
    "    \"\"\"\n",
    "    data_dict: Output from transform_data function\n",
    "    returns: Dictionary of merged datasets by year and geo-level\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "    for key, value in data_dict.items():\n",
    "        tmp_list = sorted(value, key=len, reverse=True)\n",
    "        output_dict[key] = tmp_list[0].join(tmp_list[1:])\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "def write_data(data_dict, path):\n",
    "    \"\"\"\n",
    "    data_dict: Output from merge_data function\n",
    "    Writes out all dictionary elements as csv files\n",
    "    \"\"\"\n",
    "    for key, value in data_dict.items():\n",
    "        value.to_csv(os.path.join(path,key + '.csv'), index=True, index_label=True)\n",
    "        print(f\"Writing {key} to {os.path.join(path,key + '.csv')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/edinhamzic/Symphony/wb_bangladesh/data/dhis2/health_indicators'\n",
    "WD = '/Users/edinhamzic/Symphony/wb_bangladesh/'\n",
    "OUT = '/Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>year</th>\n",
       "      <th>geo_level</th>\n",
       "      <th>file_type</th>\n",
       "      <th>abs_file_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AntenatalCare(ANC)_2017_UpazilaHealthComplex_C...</td>\n",
       "      <td>AntenatalCare(ANC)</td>\n",
       "      <td>2017</td>\n",
       "      <td>UpazilaHealthComplex</td>\n",
       "      <td>CODE</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02ChildHealth_2012_District_CODE.csv</td>\n",
       "      <td>02ChildHealth</td>\n",
       "      <td>2012</td>\n",
       "      <td>District</td>\n",
       "      <td>CODE</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05Logistics_2011_District_CODE.csv</td>\n",
       "      <td>05Logistics</td>\n",
       "      <td>2011</td>\n",
       "      <td>District</td>\n",
       "      <td>CODE</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AntenatalCare(ANC)_2016_District_CODE.csv</td>\n",
       "      <td>AntenatalCare(ANC)</td>\n",
       "      <td>2016</td>\n",
       "      <td>District</td>\n",
       "      <td>CODE</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03Immunization_2010_Upazila_NAME.csv</td>\n",
       "      <td>03Immunization</td>\n",
       "      <td>2010</td>\n",
       "      <td>Upazila</td>\n",
       "      <td>NAME</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_names     data_collection  \\\n",
       "0  AntenatalCare(ANC)_2017_UpazilaHealthComplex_C...  AntenatalCare(ANC)   \n",
       "1               02ChildHealth_2012_District_CODE.csv       02ChildHealth   \n",
       "2                 05Logistics_2011_District_CODE.csv         05Logistics   \n",
       "3          AntenatalCare(ANC)_2016_District_CODE.csv  AntenatalCare(ANC)   \n",
       "4               03Immunization_2010_Upazila_NAME.csv      03Immunization   \n",
       "\n",
       "   year             geo_level file_type  \\\n",
       "0  2017  UpazilaHealthComplex      CODE   \n",
       "1  2012              District      CODE   \n",
       "2  2011              District      CODE   \n",
       "3  2016              District      CODE   \n",
       "4  2010               Upazila      NAME   \n",
       "\n",
       "                                      abs_file_names  \n",
       "0  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "1  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "2  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "3  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "4  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dhis2_files = list_files(DATA_PATH)\n",
    "display(dhis2_files.head())\n",
    "dhis2_geos = ['Upazila', 'District']\n",
    "dhis2_years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017', '2018']\n",
    "dhis2_names = ['CODE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating, selecting/reading, summarizing, transforming and merging datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating sets\n",
    "datasets_dict = create_sets(dhis2_files, geo_levels=dhis2_geos, years=dhis2_years, file_types=dhis2_names)\n",
    "\n",
    "# Selecting and reading files\n",
    "datasets= select_sets(datasets_dict)\n",
    "\n",
    "# Summarizing datasets\n",
    "data_summary = extract_variables(datasets)\n",
    "\n",
    "# Transform and merge\n",
    "data = merge_data(transform_data(datasets))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for var in data_summary[data_summary['data_element'] == '02EPIUpazilaStock']['var_name']:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AntenatalCare(ANC)', '07Vaccine&LogisticsstockofUpazilaMunCC',\n",
       "       '03Immunization', '05Logistics',\n",
       "       '06Vaccine&LogisticsstockofDistrict', '04Newborn',\n",
       "       '01MaternalHealth', '02ChildHealth'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_summary.data_element.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Upazila_2009_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2009_CODE.csv\n",
      "Writing Upazila_2010_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2010_CODE.csv\n",
      "Writing Upazila_2011_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2011_CODE.csv\n",
      "Writing Upazila_2012_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2012_CODE.csv\n",
      "Writing Upazila_2013_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2013_CODE.csv\n",
      "Writing Upazila_2014_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2014_CODE.csv\n",
      "Writing Upazila_2015_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2015_CODE.csv\n",
      "Writing Upazila_2016_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2016_CODE.csv\n",
      "Writing Upazila_2017_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2017_CODE.csv\n",
      "Writing Upazila_2018_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/Upazila_2018_CODE.csv\n",
      "Writing District_2009_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2009_CODE.csv\n",
      "Writing District_2010_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2010_CODE.csv\n",
      "Writing District_2011_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2011_CODE.csv\n",
      "Writing District_2012_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2012_CODE.csv\n",
      "Writing District_2013_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2013_CODE.csv\n",
      "Writing District_2014_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2014_CODE.csv\n",
      "Writing District_2015_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2015_CODE.csv\n",
      "Writing District_2016_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2016_CODE.csv\n",
      "Writing District_2017_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2017_CODE.csv\n",
      "Writing District_2018_CODE to /Users/edinhamzic/Symphony/wb_bangladesh/output/dhis2/health_indicators/District_2018_CODE.csv\n"
     ]
    }
   ],
   "source": [
    "write_data(data_dict=data, path=OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_summary.to_csv(os.path.join(OUT, 'data_summary.csv'), index=False, index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
