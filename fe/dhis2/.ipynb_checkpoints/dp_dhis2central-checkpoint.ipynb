{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing - DHIS2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Input data**: Data downloaded via API from DHIS2 System. This data is stored in *data/dhis2/data* directories\n",
    "- **Processing**:\n",
    "    - Getting Upazila and District level data\n",
    "    - Reading and processing and transforming data in the following form:\n",
    "        - Rows: *Geographical levels (upazila and districts)*\n",
    "        - Columns: *Variables/health indicators*\n",
    "        - Datasets: *Years*\n",
    "- **Output data**: Processed data is stored in *data/output/dhis2/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def list_files(path):\n",
    "    \"\"\"\n",
    "    Function gets the list of all file from the target directory,\n",
    "    takes absolute path, splits file names to extract:\n",
    "    - File name\n",
    "    - Data element\n",
    "    - File type\n",
    "    - Year\n",
    "    - Geographical level/group\n",
    "    - Absolute path of the file name\n",
    "    Returns all this as a dataframe\n",
    "    \"\"\"\n",
    "    path_all = os.path.join(path, '*')\n",
    "    abs_file_names = glob.glob(path_all, recursive=True)\n",
    "    file_names = [os.path.split(glob.glob(file_path)[0])[1] for file_path in abs_file_names]\n",
    "    data_collection = [file_name.split(\"_\")[0] for file_name in file_names]\n",
    "    year = [file_name.split(\"_\")[1] for file_name in file_names]\n",
    "    geo_level = [file_name.split(\"_\")[2] for file_name in file_names]\n",
    "    file_type = [file_name[-8:-4] for file_name in file_names]\n",
    "    files_df = pd.DataFrame.from_dict({'file_names': file_names, \n",
    "                                       'data_collection': data_collection,\n",
    "                                       'year': year,\n",
    "                                       'geo_level': geo_level,\n",
    "                                       'file_type': file_type,\n",
    "                                       'abs_file_names': abs_file_names\n",
    "                                      })\n",
    "\n",
    "    return files_df\n",
    "\n",
    "def create_sets(input_df, geo_levels, years, file_types):\n",
    "    \"\"\"\n",
    "    input_df: Output from function list_files()\n",
    "    geo_levels: Defining geographic levels:\n",
    "                If as a list than it is a subset of geo levels from input_df\n",
    "                Otherwise it should ba string that specifies the column name\n",
    "    years: Defining years:\n",
    "           If as a list than it is a subset of geo levels from input_df\n",
    "           Otherwise it should ba string that specifies the column name\n",
    "    file_types: Either NAME or CODE. This is defined in the rawfiles.\n",
    "                NAME: Descriptive name of geographical unit as key ID variable\n",
    "                CODE: Geo-level code of geogrpahical unit as key ID variable\n",
    "    return: Dictionary by geo-level, year and file type\n",
    "    \"\"\"\n",
    "    df = input_df.copy(deep=True)\n",
    "    datasets = {}\n",
    "    if ((type(geo_levels) == list) & (type(years) == list)):\n",
    "        for geo_level in geo_levels:\n",
    "            for year in years:\n",
    "                for file_type in file_types:\n",
    "                    name = geo_level + '_' + year + '_' + file_type\n",
    "                    datasets[name] = df[(df['geo_level']==geo_level) &\n",
    "                                        (df['year']==year) & \n",
    "                                        (df['file_type']==file_type)] \n",
    "    else:\n",
    "        for geo_level in df[geo_levels].unique():\n",
    "            for year in df[years].unique():\n",
    "                for file_type in file_types:\n",
    "                    name = geo_level + '_' + year + '_' + file_type\n",
    "                    datasets[name] = df[(df['geo_level']==geo_level) & \n",
    "                                        (df['year']==year) & \n",
    "                                        (df['file_type']==file_type)]\n",
    "    return datasets\n",
    "\n",
    "def select_sets(datasets):\n",
    "    \"\"\"\n",
    "    datasets: Output from function create_sets\n",
    "    returns\n",
    "        - Data dictionary with loaded datasets by geo-level and year\n",
    "        # - Data frame with two columns:\n",
    "            # - List of file names with absolute paths\n",
    "            # - Logical column whether the loaded file is empty or not\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    # summary_df = {'filenames': list(), 'emptyness': list()}\n",
    "    for key, item in datasets.items():\n",
    "        data_dict[key] = dict()\n",
    "        for i in item.index:\n",
    "            tmp = pd.read_csv(item['abs_file_names'][i])\n",
    "            # summary_df['filenames'].append(os.path.split(item['abs_file_names'][i])[1])\n",
    "            # summary_df['emptyness'].append(tmp.empty)\n",
    "            data_dict[key][item['data_collection'][i]] = tmp\n",
    "    return data_dict # pd.DataFrame(summary_df)\n",
    "\n",
    "\n",
    "def extract_variables(data_dict):\n",
    "    \"\"\"\n",
    "    data_dict: Output from select_sets function\n",
    "    returns: Dataframe that summarizes all loaded files and includes following columns:\n",
    "        - variable_name: variable names if datasets is not empty otherwise it states 'No Variables'\n",
    "        - data_element: What data element from DHIS2 loaded datasets corresponds to\n",
    "        - is_empty: Is it empty or not\n",
    "        - geo_level: for example upazila or zilla\n",
    "        - year: 2009 - 2018\n",
    "    \"\"\"\n",
    "    output_dict = {'year':[], 'data_element':[], 'geo_level':[], 'var_name':[], 'is_empty':[]}\n",
    "    for key_dict, item_dict in data_dict.items():\n",
    "        for key, item in data_dict[key_dict].items():\n",
    "            if item.empty:\n",
    "                output_dict['var_name'].append('No Variables')\n",
    "                output_dict['data_element'].append(key)\n",
    "                output_dict['is_empty'].append(True)\n",
    "                output_dict['geo_level'].append(key_dict.split(\"_\")[1])\n",
    "                output_dict['year'].append(key_dict.split(\"_\")[0])\n",
    "            else:\n",
    "                for var in item['Data'].unique():\n",
    "                    output_dict['var_name'].append(var)\n",
    "                    output_dict['data_element'].append(key)\n",
    "                    output_dict['is_empty'].append(item.empty)\n",
    "                    output_dict['geo_level'].append(key_dict.split(\"_\")[1])\n",
    "                    output_dict['year'].append(key_dict.split(\"_\")[0])\n",
    "        return pd.DataFrame.from_dict(output_dict)\n",
    "\n",
    "    \n",
    "def transform_data(data_dict):\n",
    "    \"\"\"\n",
    "    data_dict: Output from function select_sets\n",
    "    returns: Dictionary (by geo-level and year) of pivoted dataframes which are not empty\n",
    "    \"\"\"\n",
    "    tdata_dict = {}\n",
    "    for key_dict, item_dict in data_dict.items():\n",
    "        tdata_dict[key_dict] = list()\n",
    "        for key, item in data_dict[key_dict].items():\n",
    "            if item.empty:\n",
    "                print('Provided dataframe is empty and therefore is not processed')\n",
    "            else:\n",
    "                tmp = pd.pivot_table(data=item, \n",
    "                                     values='Value', \n",
    "                                     index='Organisation unit',\n",
    "                                     columns='Data', \n",
    "                                     aggfunc='first')\n",
    "                tmp.columns = key + \": \" + tmp.columns\n",
    "                tdata_dict[key_dict].append(tmp)\n",
    "    return tdata_dict\n",
    "\n",
    "\n",
    "def merge_data(data_dict):\n",
    "    \"\"\"\n",
    "    data_dict: Output from transform_data function\n",
    "    returns: Dictionary of merged datasets by year and geo-level\n",
    "    \"\"\"\n",
    "    output_dict = {}\n",
    "    for key, value in data_dict.items():\n",
    "        tmp_list = sorted(value, key=len, reverse=True)\n",
    "        output_dict[key] = tmp_list[0].join(tmp_list[1:])\n",
    "    return output_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '/Users/edinhamzic/Symphony/wb_bangladesh/data/dhis2/data'\n",
    "WD = '/Users/edinhamzic/Symphony/wb_bangladesh/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>data_collection</th>\n",
       "      <th>year</th>\n",
       "      <th>geo_level</th>\n",
       "      <th>file_type</th>\n",
       "      <th>abs_file_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04EPIDistrictRequisition_2011_UpazilaandDistri...</td>\n",
       "      <td>04EPIDistrictRequisition</td>\n",
       "      <td>2011</td>\n",
       "      <td>UpazilaandDistrictlevelHF</td>\n",
       "      <td>NAME</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02EPIUpazilaStock_2010_UpazilaHealthComplex_CO...</td>\n",
       "      <td>02EPIUpazilaStock</td>\n",
       "      <td>2010</td>\n",
       "      <td>UpazilaHealthComplex</td>\n",
       "      <td>CODE</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10KMC_2011_DistrictNGO&amp;PrivateTotal_CODE.csv</td>\n",
       "      <td>10KMC</td>\n",
       "      <td>2011</td>\n",
       "      <td>DistrictNGO&amp;PrivateTotal</td>\n",
       "      <td>CODE</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11EMEN(MBFFI)_2012_DistrictNGO&amp;PrivateTotal_CO...</td>\n",
       "      <td>11EMEN(MBFFI)</td>\n",
       "      <td>2012</td>\n",
       "      <td>DistrictNGO&amp;PrivateTotal</td>\n",
       "      <td>CODE</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07EmONC_2009_UpazilaandDistrictlevelHF_NAME.csv</td>\n",
       "      <td>07EmONC</td>\n",
       "      <td>2009</td>\n",
       "      <td>UpazilaandDistrictlevelHF</td>\n",
       "      <td>NAME</td>\n",
       "      <td>/Users/edinhamzic/Symphony/wb_bangladesh/data/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_names  \\\n",
       "0  04EPIDistrictRequisition_2011_UpazilaandDistri...   \n",
       "1  02EPIUpazilaStock_2010_UpazilaHealthComplex_CO...   \n",
       "2       10KMC_2011_DistrictNGO&PrivateTotal_CODE.csv   \n",
       "3  11EMEN(MBFFI)_2012_DistrictNGO&PrivateTotal_CO...   \n",
       "4    07EmONC_2009_UpazilaandDistrictlevelHF_NAME.csv   \n",
       "\n",
       "            data_collection  year                  geo_level file_type  \\\n",
       "0  04EPIDistrictRequisition  2011  UpazilaandDistrictlevelHF      NAME   \n",
       "1         02EPIUpazilaStock  2010       UpazilaHealthComplex      CODE   \n",
       "2                     10KMC  2011   DistrictNGO&PrivateTotal      CODE   \n",
       "3             11EMEN(MBFFI)  2012   DistrictNGO&PrivateTotal      CODE   \n",
       "4                   07EmONC  2009  UpazilaandDistrictlevelHF      NAME   \n",
       "\n",
       "                                      abs_file_names  \n",
       "0  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "1  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "2  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "3  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  \n",
       "4  /Users/edinhamzic/Symphony/wb_bangladesh/data/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n",
      "Provided dataframe is empty and therefore is not processed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhis2_files = list_files(DATA_PATH)\n",
    "display(dhis2_files.head())\n",
    "dhis2_geos = ['Upazila', 'District']\n",
    "dhis2_years = ['2009','2010','2011','2012','2013','2014','2015','2016','2017', '2018']\n",
    "dhis2_names = ['NAME']\n",
    "datasets_dict = create_sets(dhis2_files, geo_levels=dhis2_geos, years=dhis2_years, file_types=dhis2_names)\n",
    "# datasets_dict = create_sets(dhis2_files, geo_levels='geo_level', years='year')\n",
    "datasets, empty, filenames = select_sets(datasets_dict)\n",
    "variable_summary = extract_variables(datasets)\n",
    "data = merge_data(transform_data(datasets))\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize missingness and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data elements (not downloaed):  ['04EPIDistrictRequisition' '05EPIDistrictSupply' '03EPIDistrictStock'\n",
      " '10KMC' '06EPIUpazilaSupply' '01EPIReport(Routinevaccination)'\n",
      " '09AdolescentHealth' '02EPIUpazilaStock' '11EMEN(MBFFI)']\n",
      "\n",
      "\n",
      "Years for which above data elements are missing: [2011, 2010, 2012, 2009, 2016, 2015, 2013, 2018, 2014, 2017]\n",
      "\n",
      "\n",
      "Geolevels for which above data elements are missing ['UpazilaandDistrictlevelHF' 'UpazilaHealthComplex'\n",
      " 'DistrictNGO&PrivateTotal' 'District' 'DistrictHospital' 'Upazila'\n",
      " 'UNICEF-MNHIdistrict' 'DistrictandNational' 'UnionandUpazilalevelHF']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empty = pd.DataFrame.from_dict({'filennames': filenames, 'emptyness':emptyness})\n",
    "print(f\"Missing data elements (not downloaed):  {empty[emptyness]['filennames'].str.split('_', expand=True)[0].unique()}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Years for which above data elements are missing: {[int(year) for year in empty[emptyness]['filennames'].str.split('_', expand=True)[1].unique()]}\")\n",
    "print(\"\\n\")\n",
    "print(f\"Geolevels for which above data elements are missing {empty[emptyness]['filennames'].str.split('_', expand=True)[2].unique()}\")\n",
    "print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
